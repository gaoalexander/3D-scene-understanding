{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from IPython.display import HTML\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "matplotlib.rcParams['figure.figsize'] = [5, 5]\n",
    "matplotlib.rcParams['figure.dpi'] = 200\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from data_helper import UnlabeledDataset, LabeledDataset\n",
    "from helper import collate_fn, draw_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/alexander/data'\n",
    "annotation_csv = '/home/alexander/data/annotation.csv'\n",
    "\n",
    "# You shouldn't change the unlabeled_scene_index\n",
    "# The first 106 scenes are unlabeled\n",
    "unlabeled_scene_index = np.arange(106)\n",
    "# The scenes from 106 - 133 are labeled\n",
    "# You should devide the labeled_scene_index into two subsets (training and validation)\n",
    "labeled_scene_index = np.arange(106, 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "# unlabeled_trainset = UnlabeledDataset(image_folder=image_folder, scene_index=labeled_scene_index, first_dim='sample', transform=transform)\n",
    "# trainloader = torch.utils.data.DataLoader(unlabeled_trainset, batch_size=3, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_trainset = LabeledDataset(image_folder=data_dir,\n",
    "                                  annotation_file=annotation_csv,\n",
    "                                  scene_index=labeled_scene_index,\n",
    "#                                   img_transform = transforms.ToTensor(),\n",
    "#                                   map_transform = None,\n",
    "                                  img_transform=transforms.Compose([transforms.CenterCrop(256),\n",
    "                                                                    transforms.ToTensor(),\n",
    "                                                                    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "                                                                   ]),\n",
    "                                  map_transform=transforms.Compose([transforms.ToPILImage(),\n",
    "                                                                    transforms.Resize(256),\n",
    "                                                                    transforms.ToTensor()\n",
    "                                                                   ]),\n",
    "                                  extra_info=True\n",
    "                                 )\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(labeled_trainset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=2,\n",
    "                                          collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 256, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_trainset[1][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 18, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "for images, road_maps in trainloader:\n",
    "    print(images.size())\n",
    "    break\n",
    "\n",
    "# # sample, target, road_image, extra = iter(trainloader).next()\n",
    "# # print(len(sample[0]))\n",
    "# # # print(torch.stack(sample).shape)\n",
    "# # print(road_image[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(road_image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The 6 images orgenized in the following order:\n",
    "# # CAM_FRONT_LEFT, CAM_FRONT, CAM_FRONT_RIGHT, CAM_BACK_LEFT, CAM_BACK, CAM_BACK_RIGHT\n",
    "# plt.imshow(torchvision.utils.make_grid(sample[4], nrow=3).numpy().transpose(1, 2, 0))\n",
    "# plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The road map layout is encoded into a binary array of size [800, 800] per sample \n",
    "# # Each pixel is 0.1 meter in physiscal space, so 800 * 800 is 80m * 80m centered at the ego car\n",
    "# # The ego car is located in the center of the map (400, 400) and it is always facing the left\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(road_image[4][0], cmap='binary');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Define a Resnet block\n",
    "    A resnet block is a conv block with skip connections\n",
    "    Original Resnet paper: https://arxiv.org/pdf/1512.03385.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, dim):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            dim (int)           -- the number of channels in the conv layer.\n",
    "            padding_type (str)  -- the name of padding layer: reflect | replicate | zero\n",
    "            use_dropout (bool)  -- if use dropout layers.\n",
    "            use_bias (bool)     -- if the conv layer uses bias or not\n",
    "        \"\"\"\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.resnet_block = nn.Sequential(nn.Conv2d(dim, dim, kernel_size=3, padding=1),\n",
    "                                          nn.BatchNorm2d(dim),\n",
    "                                          nn.ReLU(True),\n",
    "                                          nn.Dropout(0.5),\n",
    "                                          nn.Conv2d(dim, dim, kernel_size=3, padding=1),\n",
    "                                          nn.BatchNorm2d(dim)\n",
    "                                         )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.resnet_block(x)  # add skip connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    RESNET-based generator that consists of Resnet blocks + downsampling/upsampling operations.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, ngf, n_blocks=6, init_gain=0.02):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            in_ch (int)         -- the number of channels in input images\n",
    "            out_ch (int)        -- the number of channels in output images\n",
    "            ngf (int)           -- the number of filters in the last conv layer\n",
    "            n_blocks (int)      -- the number of ResNet blocks\n",
    "            padding_type (str)  -- the name of padding layer in conv layers: reflect | replicate | zero\n",
    "        \"\"\"        \n",
    "        assert(n_blocks >= 0)\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.ReflectionPad2d(3),\n",
    "            \n",
    "            nn.Conv2d(in_ch, ngf, kernel_size=7, padding=0),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.Conv2d(ngf, ngf * 2, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.Conv2d(ngf * 2, ngf * 4, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            ResnetBlock(ngf * 4),  #1\n",
    "            ResnetBlock(ngf * 4),  #2\n",
    "            ResnetBlock(ngf * 4),  #3\n",
    "            ResnetBlock(ngf * 4),  #4\n",
    "            ResnetBlock(ngf * 4),  #5\n",
    "            ResnetBlock(ngf * 4),  #6\n",
    "            ResnetBlock(ngf * 4),  #7\n",
    "            ResnetBlock(ngf * 4),  #8\n",
    "            ResnetBlock(ngf * 4),  #9\n",
    "\n",
    "            nn.ConvTranspose2d(ngf * 4, int(ngf * 2), kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(int(ngf * 2)),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 2, int(ngf), kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(int(ngf)),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(ngf, out_ch, kernel_size=7, padding=0),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_ch, ndf=64, n_layers=3):  \n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.block1 = nn.Sequential(nn.Conv2d(in_ch, ndf, kernel_size=4, stride=2, padding=1),\n",
    "                                    nn.LeakyReLU(0.2, True)\n",
    "                                   )\n",
    "        \n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        sequence2 = []        \n",
    "        for n in range(1, n_layers):  # gradually increase the number of filters\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            sequence2 += [nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=4, stride=2, padding=1),\n",
    "                         nn.BatchNorm2d(ndf * nf_mult),\n",
    "                         nn.LeakyReLU(0.2, True)\n",
    "                         ]\n",
    "        self.block2 = nn.Sequential(*sequence2)\n",
    "        \n",
    "        sequence3 = []\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n_layers, 8)\n",
    "        sequence3 += [nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=4, stride=1, padding=1),\n",
    "                     nn.BatchNorm2d(ndf * nf_mult),\n",
    "                     nn.LeakyReLU(0.2, True)\n",
    "                     ]\n",
    "        self.block3 = nn.Sequential(*sequence3)\n",
    "        \n",
    "        self.model = nn.Sequential(self.block1,\n",
    "                                   self.block2,\n",
    "                                   self.block3,\n",
    "                                   nn.Conv2d(ndf * nf_mult, 1, kernel_size=4, stride=1, padding=1)\n",
    "                                  )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_ch = 18\n",
    "out_ch = 1\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "n_blocks_g = 9\n",
    "n_layers_d = 3\n",
    "\n",
    "n_epochs = 100\n",
    "lr_g = 0.0001\n",
    "lr_d = 0.0004\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "L1_lambda = 100\n",
    "\n",
    "real_label = 0.9\n",
    "gen_label = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to generator:\t torch.Size([1, 18, 256, 256])\n",
      "\n",
      "Output of generator:\t torch.Size([1, 1, 256, 256])\n",
      "\n",
      "Input to discriminator:\t torch.Size([1, 19, 256, 256])\n",
      "\n",
      "Output of discriminator: torch.Size([1, 1, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "# Sanity check - dimensions of inputs and outputs to both networks.\n",
    "\n",
    "test = torch.zeros([1, 18, 256, 256])\n",
    "print(\"Input to generator:\\t\", test.size())\n",
    "\n",
    "test_generator = Generator(in_ch, out_ch, ngf, n_blocks=n_blocks_g, init_gain=0.02)\n",
    "test_result_g = test_generator(test)\n",
    "print(\"\\nOutput of generator:\\t\", test_result_g.size())\n",
    "\n",
    "test_d_input = torch.cat((test_result_g, test), 1)\n",
    "print(\"\\nInput to discriminator:\\t\", test_d_input.size())\n",
    "\n",
    "test_discriminator = Discriminator(in_ch + out_ch, ndf=ndf, n_layers=n_layers_d)\n",
    "test_result_d = test_discriminator(test_d_input)\n",
    "print(\"\\nOutput of discriminator:\", test_result_d.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    The GANLoss class abstracts away the need to create the target label tensor\n",
    "    that has the same size as the input.\n",
    "    \"\"\"\n",
    "    def __init__(self, gan_mode, real_label=1.0, gen_label=0.0):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            gan_mode (str) - - the type of GAN objective. It currently supports vanilla, lsgan, and wgangp.\n",
    "            target_real_label (bool) - - label for a real image\n",
    "            target_gen_label (bool) - - label of a generated image\n",
    "        Note: Do not use sigmoid as the last layer of Discriminator.\n",
    "        LSGAN needs no sigmoid. vanilla GANs will handle it with BCEWithLogitsLoss.\n",
    "        \"\"\"\n",
    "        super(GANLoss, self).__init__()\n",
    "        \n",
    "        self.gan_mode = gan_mode\n",
    "        self.real_label = real_label\n",
    "        self.gen_label = gen_label\n",
    "        \n",
    "        if gan_mode == 'LS':\n",
    "            self.loss = nn.MSELoss().to(device)\n",
    "        elif gan_mode == 'BCE':\n",
    "            self.loss = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "    def get_target_tensor(self, output, target_is_real):\n",
    "        # Create label tensors with same size as the discriminator output.\n",
    "        if target_is_real:\n",
    "            if \"cuda\" in device:\n",
    "                target_tensor = torch.cuda.FloatTensor([self.real_label])\n",
    "            else:\n",
    "                target_tensor = torch.Tensor([self.real_label])\n",
    "        else:\n",
    "            if \"cuda\" in device:\n",
    "                target_tensor = torch.cuda.FloatTensor([self.gen_label])\n",
    "            else:\n",
    "                target_tensor = torch.Tensor([self.gen_label])\n",
    "                \n",
    "        return target_tensor.expand_as(output)\n",
    "\n",
    "    def __call__(self, output, target_is_real):\n",
    "        target_tensor = self.get_target_tensor(output, target_is_real)\n",
    "        loss = self.loss(output, target_tensor)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):  # define the initialization function\n",
    "    classname = m.__class__.__name__\n",
    "    if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "        init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
    "        init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (block1): Sequential(\n",
       "    (0): Conv2d(19, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (block3): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (model): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(19, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (3): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (3): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator(in_ch, out_ch, ngf, n_blocks=n_blocks_g, init_gain=0.02).to(device)\n",
    "discriminator = Discriminator(in_ch + out_ch, ndf=ndf, n_layers=n_layers_d).to(device)\n",
    "\n",
    "generator.apply(init_weights)\n",
    "discriminator.apply(init_weights)\n",
    "\n",
    "generator.train()\n",
    "discriminator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We combine GAN Loss and L1 Loss to attain Total Loss\n",
    "criterion_gan = GANLoss('BCE', real_label=real_label, gen_label=gen_label).to(device)\n",
    "criterion_L1 = nn.L1Loss().to(device)\n",
    "\n",
    "optim_G = torch.optim.Adam(generator.parameters(), lr=lr_g, betas=(beta1, beta2))\n",
    "optim_D = torch.optim.Adam(discriminator.parameters(), lr=lr_d, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 0\n",
    "update_stats_rate = 50\n",
    "losses_g = []\n",
    "losses_d = []\n",
    "intermediate_images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/378 [00:01<11:42,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tBatch: [1/378]\n",
      "Loss_D: 1.6159\tLoss_G: 56.0310\n",
      "D(real): -0.2356  ||  D(gen) Pre-G-step: -0.2298  ||  D(gen) Post-G-step: -0.3413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 21/378 [00:11<03:40,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tBatch: [21/378]\n",
      "Loss_D: 1.4294\tLoss_G: 31.0258\n",
      "D(real): -0.1999  ||  D(gen) Pre-G-step: -0.2046  ||  D(gen) Post-G-step: -0.2130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 41/378 [00:21<03:02,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tBatch: [41/378]\n",
      "Loss_D: 1.3902\tLoss_G: 25.2355\n",
      "D(real): -0.1765  ||  D(gen) Pre-G-step: -0.1884  ||  D(gen) Post-G-step: -0.2243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 61/378 [00:31<02:54,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tBatch: [61/378]\n",
      "Loss_D: 1.4016\tLoss_G: 24.3958\n",
      "D(real): -0.2108  ||  D(gen) Pre-G-step: -0.2130  ||  D(gen) Post-G-step: -0.1722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 81/378 [00:40<02:49,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tBatch: [81/378]\n",
      "Loss_D: 1.3719\tLoss_G: 26.6460\n",
      "D(real): -0.1837  ||  D(gen) Pre-G-step: -0.2286  ||  D(gen) Post-G-step: -0.2293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 101/378 [00:49<02:25,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tBatch: [101/378]\n",
      "Loss_D: 1.4250\tLoss_G: 26.8321\n",
      "D(real): -0.0977  ||  D(gen) Pre-G-step: -0.2280  ||  D(gen) Post-G-step: -0.3516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 121/378 [01:00<02:33,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tBatch: [121/378]\n",
      "Loss_D: 1.3042\tLoss_G: 24.1908\n",
      "D(real): -0.1312  ||  D(gen) Pre-G-step: -0.3657  ||  D(gen) Post-G-step: -0.3343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 141/378 [01:09<02:15,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tBatch: [141/378]\n",
      "Loss_D: 1.2783\tLoss_G: 19.2819\n",
      "D(real): 0.0464  ||  D(gen) Pre-G-step: -0.2639  ||  D(gen) Post-G-step: -0.3404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 161/378 [01:19<02:10,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tBatch: [161/378]\n",
      "Loss_D: 1.3104\tLoss_G: 20.0129\n",
      "D(real): -0.0102  ||  D(gen) Pre-G-step: -0.3387  ||  D(gen) Post-G-step: -0.3355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 181/378 [01:28<01:46,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tBatch: [181/378]\n",
      "Loss_D: 1.2004\tLoss_G: 24.1573\n",
      "D(real): 0.4693  ||  D(gen) Pre-G-step: -0.1920  ||  D(gen) Post-G-step: -0.7360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 201/378 [01:37<01:33,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tBatch: [201/378]\n",
      "Loss_D: 1.1348\tLoss_G: 16.9678\n",
      "D(real): 0.2451  ||  D(gen) Pre-G-step: -0.5660  ||  D(gen) Post-G-step: -0.6607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 221/378 [01:46<01:19,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tBatch: [221/378]\n",
      "Loss_D: 1.5701\tLoss_G: 16.0813\n",
      "D(real): 0.1063  ||  D(gen) Pre-G-step: -0.4139  ||  D(gen) Post-G-step: -0.4692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 241/378 [01:56<01:20,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tBatch: [241/378]\n",
      "Loss_D: 0.8738\tLoss_G: 17.9817\n",
      "D(real): 0.4183  ||  D(gen) Pre-G-step: -1.2808  ||  D(gen) Post-G-step: -0.9505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 261/378 [02:06<01:05,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tBatch: [261/378]\n",
      "Loss_D: 0.9968\tLoss_G: 24.4938\n",
      "D(real): 0.1603  ||  D(gen) Pre-G-step: -1.3954  ||  D(gen) Post-G-step: -1.1841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 281/378 [02:15<00:55,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tBatch: [281/378]\n",
      "Loss_D: 2.1405\tLoss_G: 24.2041\n",
      "D(real): -0.9222  ||  D(gen) Pre-G-step: -1.7219  ||  D(gen) Post-G-step: -0.6909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 301/378 [02:25<00:42,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tBatch: [301/378]\n",
      "Loss_D: 0.9274\tLoss_G: 20.3977\n",
      "D(real): 0.1584  ||  D(gen) Pre-G-step: -1.2838  ||  D(gen) Post-G-step: -1.1451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 321/378 [02:34<00:31,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tBatch: [321/378]\n",
      "Loss_D: 0.8318\tLoss_G: 21.9775\n",
      "D(real): 0.5413  ||  D(gen) Pre-G-step: -1.5818  ||  D(gen) Post-G-step: -1.5920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 341/378 [02:44<00:20,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tBatch: [341/378]\n",
      "Loss_D: 0.5629\tLoss_G: 19.9760\n",
      "D(real): 1.1404  ||  D(gen) Pre-G-step: -1.9773  ||  D(gen) Post-G-step: -2.3403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 344/378 [02:46<00:16,  2.07it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a297023c50e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mreal_18ch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_map\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \"\"\"\n\u001b[1;32m      8\u001b[0m         \u001b[0mTRAIN\u001b[0m \u001b[0mDISCRIMINATOR\u001b[0m \u001b[0mON\u001b[0m \u001b[0mREAL\u001b[0m \u001b[0mAND\u001b[0m \u001b[0mGENERATED\u001b[0m \u001b[0mSAMPLES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DL/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DL/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DL/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DL/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DL/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DL/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DL/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DL/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DL/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DL/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####################################\n",
    "########## TRAINING LOOP ###########\n",
    "####################################\n",
    "for epoch in range(n_epochs):\n",
    "    i = 1\n",
    "    for real_18ch, real_map in tqdm(trainloader):\n",
    "        \"\"\"\n",
    "        TRAIN DISCRIMINATOR ON REAL AND GENERATED SAMPLES\n",
    "        \"\"\"\n",
    "        real_18ch = real_18ch.to(device)\n",
    "        real_map = real_map.to(device)\n",
    "        \n",
    "        gen_map = generator(real_18ch)\n",
    "        \n",
    "        real_19ch = torch.cat((real_18ch, real_map), 1).to(device)\n",
    "        gen_19ch = torch.cat((real_18ch, gen_map), 1).to(device)\n",
    "\n",
    "        output_real = discriminator(real_19ch)\n",
    "        output_gen = discriminator(gen_19ch.detach())\n",
    "        \n",
    "        d_real_mean = output_real.mean().item()\n",
    "        d_gen_mean_pre = output_gen.mean().item()\n",
    "\n",
    "        # Make label tensors.\n",
    "        target_real = torch.Tensor([real_label]).expand_as(output_real).to(device)\n",
    "        target_gen = torch.Tensor([gen_label]).expand_as(output_gen).to(device)\n",
    "\n",
    "        # Compute loss.\n",
    "        loss_d_real = criterion_gan(output_real, target_is_real=True)\n",
    "        loss_d_gen = criterion_gan(output_gen, target_is_real=False)\n",
    "        loss_d_total = (loss_d_real + loss_d_gen)\n",
    "\n",
    "        discriminator.zero_grad()\n",
    "        loss_d_total.backward()\n",
    "        optim_D.step()\n",
    "        \n",
    "        \"\"\"\n",
    "        TRAIN GENERATOR\n",
    "        \"\"\"\n",
    "        output_gen = discriminator(gen_19ch)\n",
    "        target_real = torch.Tensor([real_label]).expand_as(output_real).to(device)\n",
    "        loss_g = criterion_gan(output_gen, target_is_real=True) + L1_lambda * criterion_L1(gen_map, real_map)\n",
    "#         loss_g = criterion_gan(output_gen, target_is_real=True)\n",
    "        d_gen_mean_post = output_gen.mean().item()\n",
    "        \n",
    "        generator.zero_grad()\n",
    "        loss_g.backward()\n",
    "        optim_G.step()\n",
    "        \n",
    "        \"\"\"\n",
    "        COMPILE TRAINING STATISTICS\n",
    "        \"\"\"\n",
    "        losses_d.append(loss_d_total)\n",
    "        losses_g.append(loss_g)\n",
    "        \n",
    "        # Print out training stats\n",
    "        if i % update_stats_rate == 1:\n",
    "            print('Epoch: [%d/%d]\\tBatch: [%d/%d]\\nLoss_D: %.4f\\tLoss_G: %.4f\\nD(real): %.4f  ||  D(gen) Pre-G-step: %.4f  ||  D(gen) Post-G-step: %.4f'\n",
    "                  % (epoch + 1, n_epochs,\n",
    "                     i, len(trainloader),\n",
    "                     loss_d_total.item(), loss_g.item(),\n",
    "                     d_real_mean, d_gen_mean_pre, d_gen_mean_post))\n",
    "        \n",
    "        # Append current generated image to list of intermediate images to view post training\n",
    "        if (iters % update_stats_rate == 0) or epoch == n_epochs-1:\n",
    "            with torch.no_grad():\n",
    "                output_gen = generator(real_18ch).detach().cpu()\n",
    "            intermediate_images.append(vutils.make_grid(output_gen, padding=2, normalize=True))\n",
    "        \n",
    "        i += 1\n",
    "        iters += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(losses_g,label=\"G\")\n",
    "plt.plot(losses_d,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "fig = plt.figure()\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in intermediate_images]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=500, repeat_delay=500, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(trainloader))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
